{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSV_Read_Lidar_data(data_path):\n",
    "    rows = []\n",
    "    with open(data_path, 'r') as file:\n",
    "        csvreader = csv.reader(file)\n",
    "        for row in csvreader:\n",
    "            rows.append(row)\n",
    "\n",
    "    dataframe = pd.DataFrame([rows[0], rows[1], rows[2], rows[3]], ['Rho', 'Alpha', 'X', 'Y'])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covarience_line_fitting(points_in_line, line_alpha_rho, sigma_angle=0, sigma_dist=.005):\n",
    "    sigma_angle = sigma_angle * np.ones(len(points_in_line))\n",
    "    sigma_dist = sigma_dist * np.ones(len(points_in_line))\n",
    "\n",
    "    data = np.array(points_in_line)\n",
    "\n",
    "    #INPUIT IS X AND Y POINTS WITHIN A LINE\n",
    "    dist = line_alpha_rho[1]  # whatever positions stores the distances from 0,0\n",
    "    angle = line_alpha_rho[0]  # whatever positions stores the angles with the x axis\n",
    "    \n",
    "    x = data[:,0]\n",
    "    y = data[:,1]\n",
    "\n",
    "    n = len(x)\n",
    "    x_bar = sum(x) / n\n",
    "    y_bar = sum(y) / n\n",
    "\n",
    "    S_x2 = sum((x - x_bar) ** 2)\n",
    "    S_y2 = sum((y - y_bar) ** 2)\n",
    "    S_xy = sum((x - x_bar) * (y - y_bar))\n",
    "\n",
    "    # line paramters based on inputs data\n",
    "    alpha = 0.5 * math.atan2(-2 * S_xy, S_y2 - S_x2)\n",
    "    rho = x_bar * math.cos(alpha) + y_bar * math.sin(alpha)\n",
    "\n",
    "    C_l = np.zeros(2)\n",
    "    for i in range(0, n - 1):\n",
    "        # The covariance of the measurement\n",
    "        C_m = np.array([[sigma_angle[i], 0],\n",
    "                        [0, sigma_dist[i]]])\n",
    "        A = np.zeros((2, 2))\n",
    "\n",
    "        # The jacobian of the line fit with respect to x and y\n",
    "        A[1, 0] = ((y_bar - y[i]) * (S_y2 - S_x2) + 2 * S_xy * (x_bar - x[i])) / ((S_y2 - S_x2) ** 2 + 4 * S_xy ** 2)\n",
    "\n",
    "        A[1, 1] = ((x_bar - x[i]) * (S_y2 - S_x2) - 2 * S_xy * (y_bar - y[i])) / ((S_y2 - S_x2) ** 2 + 4 * S_xy **2)\n",
    "\n",
    "        A[0, 0] = math.cos(alpha) / n - x_bar * math.sin(alpha) * A[1, 0] + y_bar * math.cos(alpha) * A[1, 0]\n",
    "        A[0, 1] = math.sin(alpha) / n - x_bar * math.sin(alpha) * A[1, 1] + y_bar * math.cos(alpha) * A[1, 1]\n",
    "\n",
    "        # Jacobian of function converting dist and angle to x and y\n",
    "\n",
    "        B = np.array([[math.cos(angle), -dist * math.sin(angle)],\n",
    "                      [math.sin(angle), -dist * math.cos(angle)]])\n",
    "        J = A @ B\n",
    "        C_l = C_l + J * C_m * J.T\n",
    "\n",
    "    return rho, alpha, C_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bunch of algorithms for split and merge\n",
    "\n",
    "def GetPolar(X, Y):\n",
    "    # center the data\n",
    "    X = X - np.mean(X)\n",
    "    Y = Y - np.mean(Y)\n",
    "    # fit line through the first and last point (X and Y contains 2 points, start and end of the line)\n",
    "    k, n = np.polyfit(X, Y, 1)\n",
    "    alpha = math.atan(-1 / k)  # in radians\n",
    "    ro = n / (math.sin(alpha) - k * math.cos(alpha))\n",
    "    return ro, alpha\n",
    "\n",
    "def CheckPolar(ro, alpha):\n",
    "    if ro < 0:\n",
    "        alpha = alpha + math.pi\n",
    "        if alpha > math.pi:\n",
    "            alpha = alpha - 2 * math.pi\n",
    "        ro = -ro\n",
    "    return ro, alpha\n",
    "\n",
    "def getDistance(P, Ps, Pe):  # point to line distance, where the line is given with points Ps and Pe\n",
    "    if np.all(np.equal(Ps, Pe)):\n",
    "        return np.linalg.norm(P - Ps)\n",
    "    return np.divide(np.abs(np.linalg.norm(np.cross(Pe - Ps, Ps - P))), np.linalg.norm(Pe - Ps))\n",
    "\n",
    "def GetMostDistant(P):\n",
    "    dmax = 0\n",
    "    index = -1\n",
    "    for i in range(1, P.shape[0]):\n",
    "        d = getDistance(P[i, :], P[0, :], P[-1, :])\n",
    "        if (d > dmax):\n",
    "            index = i\n",
    "            dmax = d\n",
    "    return dmax, index\n",
    "\n",
    "def points_within_radius(mainpoint, points, r):\n",
    "    result = []\n",
    "    for point in points:\n",
    "        if math.dist(mainpoint, point) <= r:\n",
    "            result.append(point)\n",
    "    return result\n",
    "\n",
    "def gap_detection(lines, points, threshold):\n",
    "    good_lines = []\n",
    "    points_in_thresh_total = []\n",
    "    for i in range(len(lines)):\n",
    "        # get point 1 and point 2 of the line\n",
    "        point_1 = lines[i][0]\n",
    "        point_2 = lines[i][1]\n",
    "\n",
    "        # get the distance of the line, then take a certain percentage of it (remember its based off both sides)\n",
    "        line_dist = math.dist(point_2, point_1)\n",
    "        r = line_dist / 2 * 0.10\n",
    "        # print(r)\n",
    "\n",
    "        # check all the points to see if they fall in theshold, store if they do\n",
    "        points_in_thresh = []\n",
    "\n",
    "        for j in range(len(points)):\n",
    "            # distance = point_to_line_distance(points[j], lines[i])\n",
    "            distance = getDistance(points[j], lines[i][0], lines[i][1])\n",
    "            if distance <= (threshold * 1):\n",
    "                # if distance < r:\n",
    "                points_in_thresh.append(points[j])\n",
    "        \n",
    "        if len(points_in_thresh) <= 5 and line_dist <= 0.3:\n",
    "            good_lines.append(lines[i])\n",
    "            points_in_thresh_total.append(points_in_thresh)\n",
    "            continue\n",
    "\n",
    "        # check to see what % of points are between the threshold of the first and last point (might need my own threshold)\n",
    "        p1_points = points_within_radius(point_1, points_in_thresh, r)\n",
    "        p2_points = points_within_radius(point_2, points_in_thresh, r)\n",
    "        # print(len(p1_points))\n",
    "        # print(len(p2_points))\n",
    "        # print(len(points_in_thresh))\n",
    "\n",
    "        percent_in_radius = (len(p1_points) + len(p2_points)) / (len(points_in_thresh))\n",
    "        # print(percent_in_radius)\n",
    "\n",
    "        if percent_in_radius <= 0.40:\n",
    "            # print(\"good line\")\n",
    "            good_lines.append(lines[i])\n",
    "            points_in_thresh_total.append(points_in_thresh)\n",
    "        # else:\n",
    "        #     print(\"bad line\")\n",
    "        # plt.show()\n",
    "        # print(\"\\n\")\n",
    "        \n",
    "    return good_lines, points_in_thresh_total\n",
    "\n",
    "def SplitAndMerge(P, threshold):\n",
    "    d, ind = GetMostDistant(P)\n",
    "    if d > threshold:\n",
    "        P1 = SplitAndMerge(P[:ind + 1, :], threshold)  # split and merge left array\n",
    "        P2 = SplitAndMerge(P[ind:, :], threshold)  # split and merge right array\n",
    "        # there are 2 \"d\" points, so exlude 1 (for example from 1st array)\n",
    "        points = np.vstack((P1[:-1, :], P2))\n",
    "    else:\n",
    "        points = np.vstack((P[0, :], P[-1, :]))\n",
    "    return points\n",
    "\n",
    "def flatten(lst):\n",
    "    result = []\n",
    "    for item in lst:\n",
    "        if isinstance(item, list):\n",
    "            result.extend(flatten(item))\n",
    "        else:\n",
    "            result.append(item)\n",
    "    return result\n",
    "\n",
    "'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'\n",
    "\n",
    "def Algorithm_split_and_merge(inputdataframe, threshold=0.3, plot=False):\n",
    "\n",
    "    P = np.array([list(inputdataframe['X']), list(inputdataframe['Y'])]).T\n",
    "\n",
    "    points = SplitAndMerge(P, threshold)\n",
    "\n",
    "    lines = []\n",
    "    for i in range(len(points) - 1):\n",
    "        lines.append([points[i], points[i + 1]])\n",
    "        # plt.plot([points[i][0], points[i+1][0]], [points[i][1], points[i+1][1]], '-o')\n",
    "    # final_lines = lines\n",
    "    final_lines, points_in_line = gap_detection(lines, P, threshold)\n",
    "\n",
    "    # flatten it to get the shitty points\n",
    "    flat_list = flatten(final_lines)\n",
    "    flat_list.append(flat_list[0])\n",
    "    flat_list = np.array(flat_list)\n",
    "\n",
    "    #convert from xy back to alpha rho\n",
    "    alpha_rho = []\n",
    "    for i in range(len(final_lines)):\n",
    "        alpha, rho = GetPolar([final_lines[i][0][0], final_lines[i][1][0]], [final_lines[i][0][1], final_lines[i][1][1]])\n",
    "        alpha_rho.append([alpha, rho])\n",
    "\n",
    "    if plot==True:\n",
    "        plt.figure()\n",
    "        plt.title('og')\n",
    "        plt.scatter(P[:, 0], P[:, 1], c='black')\n",
    "        plt.plot(points[:, 0], points[:, 1])\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title('with gap detection')\n",
    "        plt.scatter(P[:, 0], P[:, 1], c='black')\n",
    "        plt.plot(flat_list[:, 0], flat_list[:, 1], '-o')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title('actual Lines')\n",
    "        plt.scatter(P[:, 0], P[:, 1], c='black')\n",
    "        for i in range(len(final_lines)):\n",
    "            tmp = np.array(final_lines[i])\n",
    "            plt.plot(tmp[:, 0], tmp[:, 1], '-o')\n",
    "        # print(len(lines))\n",
    "        # print(len(final_lines))\n",
    "        plt.scatter(0, 0, c='red')  # replace this with the origin point\n",
    "        plt.show()\n",
    "\n",
    "    return final_lines, points_in_line, alpha_rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(z_hat_t,z_t,R_t,H_j,g_thresh,P_hat_t,g):\n",
    "\n",
    "    matches = []\n",
    "    v_t_matches = []\n",
    "    sigmas_matches = []\n",
    "    H_matches = []\n",
    "    #initializedng vt\n",
    "    \n",
    "    v_t = np.zeros((2,2,len(z_t),len(z_hat_t)))\n",
    "    sigma_itt = np.zeros((2,2,len(z_t),len(z_hat_t)))\n",
    "    #This could be vectorized or whatever but i think itll be okay\n",
    "    for i in range(len(z_t)):\n",
    "        for j in range(len(z_hat_t)):\n",
    "            v_t[:,:,i,j] = z_t[i]-z_hat_t[j]\n",
    "\n",
    "            sigma_itt[:,:,i,j] = H_j[j] @ P_hat_t @ H_j[j].T + R_t(i)\n",
    "\n",
    "    # Mahalanobis distance\n",
    "    for i in range(len(z_t)):\n",
    "        for j in range(len(z_hat_t)):\n",
    "            v_ = v_t[:,i,j]\n",
    "            sigma_ = sigma_itt[:,:,i,j]\n",
    "\n",
    "            mah_dist = v_.T @ sigma_ @ v_\n",
    "            if mah_dist <= g**2:\n",
    "                matches.append([i,j])\n",
    "                v_t_matches.append(v_t[:,:,i,j])\n",
    "                sigmas_matches.append(sigma_itt[:,:,i,j])\n",
    "                H_matches.append(H_j[j])\n",
    "    return matches, v_t_matches, sigmas_matches,H_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_estimation(H_t, x_hat, v_t,P_t_hat,sigmas):\n",
    "    \n",
    "    \n",
    "    for i in len(x_hat):\n",
    "        K_t = P_t_hat[i] @ H_t[i].T @ np.linalg.pinv(sigmas[i])\n",
    "        P_t = P_t_hat[i] - K_t @ sigmas[i] @ K_t.T\n",
    "        x_t = x_hat + K_t @ v_t[i]\n",
    "        x_hat = x_t\n",
    "\n",
    "\n",
    "    return x_t, P_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_prediction(x_hat, map, data):\n",
    "    \"\"\"\n",
    "    The measurements needs to take the MAP data and move the lines into the Robts frame (from world) THEN match lines together or something\n",
    "    \"\"\"\n",
    "    N = len(map)\n",
    "    z_hat_t = np.zeros(2,1,N) # The pridiction of what the Lines detected should be, from map\n",
    "    alpha_map = data.alphas\n",
    "    rho_map = data.rhos\n",
    "    z_hat_t[0,1,:] = alpha_map[:] - x_hat[2] # removing the robots orientation in the world to rotate the line angles into frame\n",
    "    z_hat_t[1,1,:] = rho_map[:]-x_hat[0]*np.cos(alpha_map[:])+x_hat[1]*np.sin(alpha_map[:]) # translation portion for the lines\n",
    "    H_j = np.zeros(2,3,N)\n",
    "\n",
    "    H_j[0:1,0:2,:] = np.array([[0,  0,  -1],  \n",
    "                  [-np.cos(alpha_map[:]), -np.sin(alpha_map[:]), 0]])  #it might not be able to handle this notation. Could easily be a loop\n",
    "\n",
    "    return z_hat_t,H_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation(data):\n",
    "    \"\"\"\n",
    "    the obsorvation step should spin the lidar, calculate and return the lines in the robot's frame (at timestep t)\n",
    "\n",
    "    \"\"\"\n",
    "    N = len(data)\n",
    "    z_t = np.zeros(2,1,N)  # z_t^i = [alpha_t^i, r_t^i]^T for 0<i<N lines\n",
    "    R_t = np.zeros(2,2,N)\n",
    "\n",
    "    z_t[0,1,:] = data.alphas \n",
    "    z_t[1,1,:] = data.rhos\n",
    "\n",
    "\n",
    "    R_t = data.cov[:]\n",
    "\n",
    "    return z_t,R_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_prediction(pos_t_minus1, delta_sl, delta_sr, b, k_r, k_l, F_k_minus_1, Q_t):\n",
    "\n",
    "    delta_sl\n",
    "    delta_sr\n",
    "    theta_t_minus1 = pos_t_minus1[2,1]\n",
    "     \n",
    "    x_hat = np.empty((3,1))\n",
    "\n",
    "    # This is previous postion + estimate of future position\n",
    "    x_hat = pos_t_minus1 + np.array([(delta_sr+delta_sl)/2*math.cos(theta_t_minus1+(delta_sr-delta_sl)/2/b)],\n",
    "                                    [(delta_sr+delta_sl)/2*math.sin(theta_t_minus1+(delta_sr-delta_sl)/2/b)],\n",
    "                                    [(delta_sr-delta_sl)/b])\n",
    "    \n",
    "    # covarieance of the previouse robot state\n",
    "    P_t_minus1 = np.array([k_r*abs(delta_sr), 0],\n",
    "                           [0,k_l*abs(delta_sl) ])\n",
    "    \n",
    "    # @ is matrix multiplication\n",
    "    P_hat_t = F_k_minus_1 @ P_t_minus1 @ F_k_minus_1.T + Q_t \n",
    "    return x_hat, P_hat_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Robot Position Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some values that are global\n",
    "\n",
    "# Parameters for the robot \n",
    "# TODO this will be pulled from ros later\n",
    "x_vel = 0.75\n",
    "y_vel = 0.0\n",
    "z_vel = 0.0\n",
    "\n",
    "b = .235 # distance between robots wheels (meters)\n",
    "wheel_radius = 0.072 # radius of the actual wheel (meters)\n",
    "\n",
    "\"\"\"\n",
    "These are the uncertainties in the are error constants representing the \n",
    "nondeterministic parameters of the motor drive and the wheel-floor interaction. Probably can be found in DOC or just tune for it\n",
    "\"\"\"\n",
    "k_r =  .001\n",
    "k_l =  .001\n",
    "\n",
    "Q_t  = np.array([[1.0,   0],\n",
    "                [  0, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull these from ros, page 337, displacewmnt of left and right wheel\n",
    "# ut = [delta_sl, delta_sr].T\n",
    "#TODO these are placeholder values\n",
    "delta_sl = 0.5\n",
    "delta_sr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_t_minus1 is the [x_t-1, y_t-1, theta_t-1] position of the robot x_t-1\n",
    "# the robot drives forward with the control input ut (above) to a position vector xt\n",
    "# Both are world frames\n",
    "#TODO get a value for this\n",
    "pos_t_minus1 = 0.69420\n",
    "\n",
    "#TODO idk wtf this is\n",
    "F_k_minus_1 = 0.42069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "position_prediction() missing 8 required positional arguments: 'pos_t_minus1', 'delta_sl', 'delta_sr', 'b', 'k_r', 'k_l', 'F_k_minus_1', and 'Q_t'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/risl/Documents/GitHub/-ME580Robotics/sutfftosend/kalmanfilter.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/risl/Documents/GitHub/-ME580Robotics/sutfftosend/kalmanfilter.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m position_prediction()\n",
      "\u001b[0;31mTypeError\u001b[0m: position_prediction() missing 8 required positional arguments: 'pos_t_minus1', 'delta_sl', 'delta_sr', 'b', 'k_r', 'k_l', 'F_k_minus_1', and 'Q_t'"
     ]
    }
   ],
   "source": [
    "x_hat, P_hat_t = position_prediction(pos_t_minus1, delta_sl, delta_sr, b, k_r, k_l, F_k_minus_1, Q_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground Truth Map Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datapath and put into dataframe\n",
    "# path to csv data\n",
    "data_path = 'DownstairsGTdata.csv'\n",
    "gt_map_df = CSV_Read_Lidar_data(data_path)\n",
    "gt_map_df = gt_map_df.astype(float)\n",
    "\n",
    "# Delete any column that has an inf in the rho spot\n",
    "inf_cols = gt_map_df.loc['Rho'][np.isfinite(gt_map_df.loc['Rho'])]\n",
    "gt_map_df = gt_map_df[inf_cols.index].transpose().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the ground truth data\n",
    "# plt.figure()\n",
    "# plt.scatter(gt_map_df['X'], gt_map_df['Y'], s=1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the split and merge algorithm\n",
    "Lines, points_in_line, line_alpha_rho = Algorithm_split_and_merge(gt_map_df.astype(float),threshold=0.1, plot=False)\n",
    "\n",
    "# Do covarience line fitting, save data to lists\n",
    "alphas = []\n",
    "rhos = []\n",
    "covars = []\n",
    "for i in range(len(points_in_line)):\n",
    "    rho, alpha, C_l = covarience_line_fitting(points_in_line[i], line_alpha_rho[i])\n",
    "    # line_info.append([alpha, rho, C_l])\n",
    "    alphas.append(alpha)\n",
    "    rhos.append(rho)\n",
    "    covars.append(C_l)\n",
    "\n",
    "# Create a dataframe with the good info\n",
    "ground_truth_df = pd.DataFrame([alphas, rhos, covars, Lines, points_in_line], ['Alpha','rhos' ,'Covariance', 'Lines (endpoints)', ' Points within line'])\n",
    "# ground_truth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Measuremnt Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
